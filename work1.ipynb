{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/e3sl4eawJpHYlJRpwPrS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/e-s-23/Prog2kakushin/blob/main/work1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pandasを用いた辞書プログラム\n"
      ],
      "metadata": {
        "id": "SVJlqNeI-8Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#一時的なテキストファイル作成\n",
        "%%bash\n",
        "cat <<EOF > input3.txt\n",
        "#テキストを入力\n",
        "EOF"
      ],
      "metadata": {
        "id": "4pQfw8dL0NZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsS1yuAQ-Yn8"
      },
      "outputs": [],
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def file_open(name):\n",
        "  try:\n",
        "    with open(name,\"r\") as f:\n",
        "      txt = f.read()\n",
        "      Re_txt = txt.replace('\\n','')\n",
        "      print(Re_txt)\n",
        "\n",
        "  except FileNotFoundError:\n",
        "      txt = file_open(str(input(\"そのファイルは存在しません。再入力してください:\")))\n",
        "\n",
        "  return Re_txt\n",
        "\n",
        "\n",
        "def check_decimal(x): #整数値の判定\n",
        "  if(type(x) == int):\n",
        "    pass\n",
        "\n",
        "  else:\n",
        "    x = check_decimal(int(input(\"整数値を入力してください:\")))\n",
        "\n",
        "  return x\n",
        "\n",
        "def adjust_df(S): #データフレームの調整\n",
        "\n",
        "  S2 = sorted(S.items(), key = lambda x:x[1],reverse = True)\n",
        "\n",
        "  s = check_decimal(int(input(\"上位何件に絞り込みますか:\")))\n",
        "  S3 = S2[:s]\n",
        "\n",
        "  df = pd.DataFrame(S3,columns = [\"単語\",\"回数\"])\n",
        "  col = str(input(\"何のデータを追加しますか？\"))\n",
        "\n",
        "  if (col == \"\"): #空値なら追加しない\n",
        "    pass\n",
        "\n",
        "  else:\n",
        "    df[col] = 0\n",
        "\n",
        "    for i in range(len(df)):\n",
        "      df.iat[i,2] = str(input(str(df.iat[i,0]) + \"の\" + col + \"を入力してください:\"))\n",
        "\n",
        "  return df\n",
        "\n",
        "t = Tokenizer()\n",
        "stat = {} #辞書設定\n",
        "file_name = str(input(\"ファイル名:\"))\n",
        "text = file_open(file_name)\n",
        "part = str(input(\"集計する品詞を指定してください:\"))\n",
        "\n",
        "# トークン列に分解\n",
        "for tok in t.tokenize(text):\n",
        "    pos = tok.part_of_speech.split(',')   # 品詞を分解\n",
        "    if (part) in pos:                     # 品詞の有無を判定\n",
        "        if tok.surface in stat.keys():    # 統計にそのワードがあるか\n",
        "            stat[tok.surface] += 1\n",
        "        else:                             # 新規カウントする\n",
        "            stat[tok.surface] = 1\n",
        "\n",
        "a_df = adjust_df(stat)\n",
        "\n",
        "a_df.to_csv(file_name + \"(shit-jis).csv\",encoding = \"shift-jis\")\n",
        "a_df.to_csv(file_name + \"(utf-8).csv\",encoding = \"utf-8\")\n",
        "\n",
        "a_df"
      ]
    }
  ]
}